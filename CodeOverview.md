## A basic overview of the structure of the code - 

*
    Directory 1 - 
    ğŸ“¦data_samples
    â”£ ğŸ This directory contains a short 1000 word-text sample for each of the 11 datasets used in the paper.
    â”£ ğŸ“œREADME.md
    â”£ ğŸ“œaae.txt
    â”£ ğŸ“œbible.txt
    â”£ ğŸ“œcoha_1810-1830.txt
    â”£ ğŸ“œcoha_1890-1910.txt
    â”£ ğŸ“œcoha_1990-2000.txt
    â”£ ğŸ“œenglish_tweets.txt
    â”£ ğŸ“œjoyce.txt
    â”£ ğŸ“œlyrics.txt
    â”£ ğŸ“œromantic_poetry.txt
    â”£ ğŸ“œshakespeare.txt
    â”— ğŸ“œswitchboard.txt

*   
    Directory 2 -
    ğŸ“¦datasets
    â”£ ğŸ Directory with scripts to play around with the datasets
    â”£ ğŸ™‡ğŸ»â€â™‚ï¸ (Links) - 
        â”£ https://en.wikipedia.org/wiki/Byte_pair_encoding
        â”£ https://ai.facebook.com/blog/roberta-an-optimized-method-for-pretraining-self-supervised-nlp-systems/
    â”£ ğŸ“œ.gitignore
    â”£ ğŸ“œbpe2binary.sh - Pre-processing configs for FairSeq(SMT) models | BPE to Binary - setting paths for train/valid/dev tests and dictionary
    â”£ ğŸ“œbpe2text.py - Decoding the byte-pair encoded data to normal text data.
    â”£ ğŸ“œdataset2bpe.py - Converting dataset to BPE
    â”£ ğŸ“œparaphrase_splits.py - Split the datasets into train, dev, test. Create minibatches for all and store as BPE.
    â”£ ğŸ“œparse_paranmt_postprocess.py - A part of it cleans the data by removing non-English labels in the paraphrase data. Not 100% sure about the rest yet.
    â”— ğŸ“œpreprocess_utils.py - General Utils class. 

* 
    Directory 3 - 
    ğŸ“¦fairseq
    â”£ ğŸ Clone of the FairSeq repo by Facebook which literally contains every SOTA implementation regarding Seq2Seq from basic NERs to the best transformer models out there. The saviour from the satan called Transformer(and it's training) ğŸ¤©
    â”£ ğŸ™‡ğŸ»â€â™‚ï¸ 
       â”£ https://github.com/pytorch/fairseq - Pytorch
       â”£ https://ai.facebook.com/tools/fairseq/
       â”£ https://cloud.google.com/tpu/docs/tutorials/transformer-pytorch - Something we might find ourselves using in Phase2.

* 
    Directory 4 - 
    ğŸ“¦outputs
    â”£ Essentially an output sample of the results for each of the 11 datasets. The HTML formats are intersting, run it once and there are some good examples in here! I think there are more classes in here than the paper mentions(will need to confirm), like the lyrics style transfer.

* 
    Directory 5 - The ultimate directory, brace yourself ğŸ
    ğŸ“¦style_paraphrase
    â”£ ğŸ“‚evaluation
    â”ƒ â”£ ğŸ“‚human
    â”ƒ â”ƒ â”£ ğŸ“œcrowdsourcing.png
    â”ƒ â”ƒ â”£ ğŸ“œcrowdsourcing2.png
    â”ƒ â”ƒ â”£ ğŸ“œcrowdsourcing3.png
    â”ƒ â”ƒ â”£ ğŸ“œcrowdsourcing4.png
    â”ƒ â”ƒ â”— ğŸ“œparaphrase_amt_template.html - File to work on manual annotation, not sure we will be doing it, but if we are than this is amazing.
    â”ƒ â”£ ğŸ“‚scripts
    â”ƒ â”ƒ â”£ ğŸ“œacceptability.py - This is CoLa benchmark implemented with Roberta. Res: https://nyu-mll.github.io/CoLA/
    â”ƒ â”ƒ â”£ ğŸ“œevaluate_formality.sh - Script to evaulate formality: Convert formal to informal and vice-versa and evaluate over all 5 metrics.
    â”ƒ â”ƒ â”£ ğŸ“œevaluate_shakespeare.sh - Same as above for shakespeare.
    â”ƒ â”ƒ â”£ ğŸ“œflip_labels.py
    â”ƒ â”ƒ â”£ ğŸ“œget_paraphrase_similarity.py - A helper file to get sentence similarity (as we will discuss in the next sub-dir)
    â”ƒ â”ƒ â”£ ğŸ“œmicro_eval.py - Here a final metric is defined which is a formula combining all the 5 metrics.
    â”ƒ â”ƒ â”£ ğŸ“œroberta_classify.py - 
    â”ƒ â”ƒ â”£ ğŸ“œstyle_transfer.py
    â”ƒ â”ƒ â”— ğŸ“œutils.py
    â”ƒ â”£ ğŸ“‚similarity
    â”ƒ â”ƒ â”£ ğŸ“œ__init__.py
    â”ƒ â”ƒ â”£ ğŸ“œsim_models.py
    â”ƒ â”ƒ â”£ ğŸ“œsim_utils.py
    â”ƒ â”ƒ â”£ ğŸ“œspm.py
    â”ƒ â”ƒ â”— ğŸ“œtest_sim.py
    â”ƒ â”£ ğŸ“œ.gitignore
    â”ƒ â”— ğŸ“œREADME.md
    â”£ ğŸ“‚examples
    â”ƒ â”£ ğŸ“‚formality
    â”ƒ â”ƒ â”£ ğŸ“œrun_finetune_formality_0.sh
    â”ƒ â”ƒ â”— ğŸ“œrun_finetune_formality_1.sh
    â”ƒ â”£ ğŸ“‚shakespeare
    â”ƒ â”ƒ â”£ ğŸ“œrun_finetune_shakespeare_0.sh
    â”ƒ â”ƒ â”— ğŸ“œrun_finetune_shakespeare_1.sh
    â”ƒ â”£ ğŸ“œrun_evaluate_paraphrase.sh
    â”ƒ â”£ ğŸ“œrun_finetune_inverse_paraphrase.sh
    â”ƒ â”— ğŸ“œrun_finetune_paraphrase.sh
    â”£ ğŸ“‚logs
    â”ƒ â”— ğŸ“œ.gitkeep
    â”£ ğŸ“‚runs
    â”ƒ â”— ğŸ“œ.gitkeep
    â”£ ğŸ“‚saved_models
    â”ƒ â”— ğŸ“œ.gitkeep
    â”£ ğŸ“‚slurm-schedulers
    â”ƒ â”— ğŸ“œ.gitkeep
    â”£ ğŸ“‚style_classify
    â”ƒ â”£ ğŸ“‚examples
    â”ƒ â”ƒ â”£ ğŸ“œtrain_cds.sh
    â”ƒ â”ƒ â”£ ğŸ“œtrain_cola.sh
    â”ƒ â”ƒ â”£ ğŸ“œtrain_formality.sh
    â”ƒ â”ƒ â”— ğŸ“œtrain_shakespeare.sh
    â”ƒ â”£ ğŸ“‚webapp
    â”ƒ â”ƒ â”£ ğŸ“‚static
    â”ƒ â”ƒ â”ƒ â”— ğŸ“œ.gitkeep
    â”ƒ â”ƒ â”£ ğŸ“‚templates
    â”ƒ â”ƒ â”ƒ â”£ ğŸ“œresults.html
    â”ƒ â”ƒ â”ƒ â”— ğŸ“œvisual.html
    â”ƒ â”ƒ â”£ ğŸ“œapp.py
    â”ƒ â”ƒ â”— ğŸ“œrun.sh
    â”ƒ â”£ ğŸ“œ.gitignore
    â”ƒ â”£ ğŸ“œauthor_classify_template.sh
    â”ƒ â”— ğŸ“œschedule.py
    â”£ ğŸ“œ.DS_Store
    â”£ ğŸ“œ.gitignore
    â”£ ğŸ“œ__init__.py
    â”£ ğŸ“œargs.py
    â”£ ğŸ“œdata_utils.py
    â”£ ğŸ“œdataset_config.py
    â”£ ğŸ“œhyperparameters_config.py
    â”£ ğŸ“œinference_utils.py
    â”£ ğŸ“œrun_evaluate_gpt2_template.sh
    â”£ ğŸ“œrun_finetune_gpt2_template.sh
    â”£ ğŸ“œrun_generation.py
    â”£ ğŸ“œrun_generation_gpt2_template.sh
    â”£ ğŸ“œrun_lm_finetuning.py
    â”£ ğŸ“œschedule.py
    â”£ ğŸ“œstyle_dataset.py
    â”— ğŸ“œutils.py 

